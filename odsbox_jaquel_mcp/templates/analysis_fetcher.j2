#!/usr/bin/env python3
"""
Submatrix Data Analysis Script
Fetches data and performs comprehensive analysis
"""

import logging
import sys
import pandas as pd
import numpy as np
from odsbox import ConI

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def perform_statistical_analysis(df):
    """Perform comprehensive statistical analysis."""
    logger.info("=== STATISTICAL ANALYSIS ===")
    logger.info(f"Shape: {df.shape}")
    logger.info(f"Data Types:\n{df.dtypes}")

    missing = df.isnull().sum()
    if missing.sum() > 0:
        logger.info(f"Missing Values:\n{missing[missing > 0]}")

    logger.info(f"Descriptive Statistics:\n{df.describe()}")

    return {
        'shape': df.shape,
        'missing_values': int(missing.sum()),
        'numeric_columns': len(df.select_dtypes(include=[np.number]).columns),
    }

def main():
    ODS_URL = "http://localhost:8087/api"
    ODS_USERNAME = "your_username"
    ODS_PASSWORD = "your_password"
    SUBMATRIX_ID = {{ submatrix_id }}
    COLUMN_PATTERNS = [{% for qty in measurement_quantities %}"{{ qty }}"{{ ", " if not loop.last }}{% endfor %}]
    OUTPUT_FORMAT = "{{ output_format }}"

    try:
        with ConI(url=ODS_URL, auth=(ODS_USERNAME, ODS_PASSWORD)) as con_i:
            logger.info("Connected to ODS server")

            logger.info(f"Fetching data from submatrix {SUBMATRIX_ID}")
            df = con_i.bulk.data_read(
                submatrix_iid=SUBMATRIX_ID,
                column_patterns=COLUMN_PATTERNS,
                date_as_timestamp=True,
                set_independent_as_index=True
            )

        logger.info(f"Data loaded: shape={df.shape}")
        stats = perform_statistical_analysis(df)

        output_file = f"submatrix_{SUBMATRIX_ID}_analysis.{OUTPUT_FORMAT}"
        if OUTPUT_FORMAT == "csv":
            df.to_csv(output_file, index=True)
        elif OUTPUT_FORMAT == "json":
            df.to_json(output_file, orient="records", indent=2, date_format="iso")
        elif OUTPUT_FORMAT == "parquet":
            df.to_parquet(output_file)
        elif OUTPUT_FORMAT == "excel":
            df.to_excel(output_file, index=True)

        logger.info(f"Data saved to {output_file}")
        logger.info("Analysis completed successfully!")

    except Exception as e:
        logger.error(f"Analysis failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
